{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f6d853-3ab4-4a05-a9c1-feedf8cecaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import LiverTumorDataset\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df976484-4856-4e64-9dff-0d33e09e4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b49c2f-6a14-44b3-be87-631d389238f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    intersection = (pred * target).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "bce = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ae79fe-f650-437a-a06b-f260f58d0470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from Stage 6\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"unet_liver_stage_6.pth\"))\n",
    "print(\"Loaded checkpoint from Stage 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63df5df1-b346-47e9-95d0-3dfb91bd60e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resuming training on chunk_6.txt (Chunk 7/10)\n",
      "Chunk 7 | Epoch 1/2 | Loss: 0.1760\n",
      "Chunk 7 | Epoch 2/2 | Loss: 0.1747\n",
      "\n",
      "Resuming training on chunk_7.txt (Chunk 8/10)\n",
      "Chunk 8 | Epoch 1/2 | Loss: 0.1781\n",
      "Chunk 8 | Epoch 2/2 | Loss: 0.1794\n",
      "\n",
      "Resuming training on chunk_8.txt (Chunk 9/10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResuming training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/10)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m LiverTumorDataset(chunk_file, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs_per_chunk):\n\u001b[0;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:383\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 383\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:165\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "chunk_files = [f\"chunk_{i}.txt\" for i in range(6, 10)]  # chunk_6 to chunk_9\n",
    "epochs_per_chunk = 2\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "for chunk_id, chunk_file in enumerate(chunk_files, start=6):\n",
    "    print(f\"\\nResuming training on {chunk_file} (Chunk {chunk_id+1}/10)\")\n",
    "\n",
    "    train_dataset = LiverTumorDataset(chunk_file, image_size=(256, 256))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "    for epoch in range(epochs_per_chunk):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = 0.5 * bce(outputs, masks) + 0.5 * dice_loss(outputs, masks)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Chunk {chunk_id+1} | Epoch {epoch+1}/{epochs_per_chunk} | Loss: {avg_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"unet_liver_stage_{chunk_id+1}.pth\")\n",
    "\n",
    "# Final save\n",
    "torch.save(model.state_dict(), \"unet_liver.pth\")\n",
    "print(\"Final model saved as unet_liver.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ee26bd-c8c3-4ef7-8b43-3f65d02b067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model as unet_liver_final.pth\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"unet_liver_stage_8.pth\"))\n",
    "torch.save(model.state_dict(), \"unet_liver_final.pth\")\n",
    "print(\"Saved model as unet_liver_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21d7c3-0ae7-430b-ad32-44c37f999b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
